# CoexistAI 12-Factor Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
PORT=8000
HOST=0.0.0.0
LOG_LEVEL=INFO
PLACE=UTC
LOCATION=Local Area

# =============================================================================
# SEARXNG SEARCH ENGINE CONFIGURATION
# =============================================================================
SEARXNG_HOST=searxng
SEARXNG_PORT=8080
SEARXNG_PROTOCOL=http

# =============================================================================
# LLM (LARGE LANGUAGE MODEL) CONFIGURATION
# =============================================================================

# Choose your LLM provider: google, openai, local, groq, others
LLM_TYPE=google

# Model name (depends on provider)
# Google: gemini-2.0-flash, gemini-1.5-pro, etc.
# OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo, etc.
# Local: llama3.2, mistral, etc. (depends on your local server)
LLM_MODEL_NAME=gemini-2.0-flash

# LLM Generation Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=  # Leave empty for default
LLM_TIMEOUT=     # Leave empty for default
LLM_MAX_RETRIES=2

# API Keys (set based on your LLM_TYPE)
# For Google Gemini:
GOOGLE_API_KEY=your-google-api-key-here

# For OpenAI:
OPENAI_API_KEY=your-openai-api-key-here

# For Groq:
GROQ_API_KEY=your-groq-api-key-here

# For Local models (usually not needed):
LLM_API_KEY=DUMMY

# API Base URLs (for custom/openai-compatible endpoints)
GOOGLE_API_BASE=https://generativelanguage.googleapis.com/v1beta/openai/
OPENAI_API_BASE=https://api.openai.com/v1
GROQ_API_BASE=https://api.groq.com/openai/v1
LOCAL_API_BASE=http://localhost:11434/v1
OTHERS_API_BASE=https://openrouter.ai/api/v1

# =============================================================================
# EMBEDDING MODEL CONFIGURATION
# =============================================================================

# Embedding model name
# Google: models/embedding-001
# OpenAI: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
# Local: nomic-ai/nomic-embed-text-v1, sentence-transformers/all-MiniLM-L6-v2, etc.
EMBEDDING_MODEL_NAME=models/embedding-001

# Embedding backend: google, openai, infinity_emb, huggingface
EMBED_MODE=google

# Embedding API key (can be same as LLM_API_KEY for some providers)
EMBED_API_KEY=your-embedding-api-key-here

# Cross-encoder model for reranking
CROSS_ENCODER_NAME=BAAI/bge-reranker-base

# Infinity embedding server (for local embeddings)
INFINITY_EMB_URL=http://localhost:7997

# =============================================================================
# ADVANCED CONFIGURATION
# =============================================================================

# Wait for these services before starting (format: host:port,host:port)
WAIT_FOR_SERVICES=searxng:8080

# Docker network configuration
DOCKER_NETWORK=coexistai-network

# Volume mounts
DOCUMENTS_PATH=./documents
OUTPUT_PATH=./output

# =============================================================================
# EXAMPLE CONFIGURATIONS
# =============================================================================

# --- GOOGLE GEMINI (Default) ---
# LLM_TYPE=google
# LLM_MODEL_NAME=gemini-2.0-flash
# LLM_API_KEY=${GOOGLE_API_KEY}
# EMBEDDING_MODEL_NAME=models/embedding-001
# EMBED_MODE=google
# EMBED_API_KEY=${GOOGLE_API_KEY}

# --- OPENAI ---
# LLM_TYPE=openai
# LLM_MODEL_NAME=gpt-4o-mini
# LLM_API_KEY=${OPENAI_API_KEY}
# EMBEDDING_MODEL_NAME=text-embedding-3-small
# EMBED_MODE=openai
# EMBED_API_KEY=${OPENAI_API_KEY}

# --- LOCAL OLLAMA ---
# LLM_TYPE=local
# LLM_MODEL_NAME=llama3.2
# LOCAL_API_BASE=http://localhost:11434/v1
# LLM_API_KEY=DUMMY
# EMBEDDING_MODEL_NAME=nomic-ai/nomic-embed-text-v1
# EMBED_MODE=infinity_emb
# INFINITY_EMB_URL=http://localhost:7997

# --- GROQ ---
# LLM_TYPE=groq
# LLM_MODEL_NAME=llama-3.1-70b-versatile
# LLM_API_KEY=${GROQ_API_KEY}
# EMBEDDING_MODEL_NAME=models/embedding-001
# EMBED_MODE=google
# EMBED_API_KEY=${GOOGLE_API_KEY}

# --- CUSTOM OPENAI-COMPATIBLE ---
# LLM_TYPE=others
# LLM_MODEL_NAME=your-model-name
# OTHERS_API_BASE=https://your-custom-endpoint.com/v1
# LLM_API_KEY=your-custom-api-key
# EMBEDDING_MODEL_NAME=your-embedding-model
# EMBED_MODE=others
# EMBED_API_KEY=your-custom-api-key